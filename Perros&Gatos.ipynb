{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "cwy2nhA9o_UH"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import tensorflow_datasets as tfds\n",
        "\n",
        "#Correccion temporal (22/mayo/2022)\n",
        "#Tensorflow datasets tiene error al descargar el set de perros y gatos y lo solucionaron\n",
        "#el 16 de mayo pero sigue fallando en los colabs. Entonces se agrega esta linea adicional\n",
        "#Mas detalle aqui: https://github.com/tensorflow/datasets/issues/3918\n",
        "setattr(tfds.image_classification.cats_vs_dogs, '_URL',\"https://download.microsoft.com/download/3/E/1/3E1C3F21-ECDB-4869-8368-6DEBA77B919F/kagglecatsanddogs_5340.zip\")\n",
        "\n",
        "#Descargar el set de datos de perros y gatos\n",
        "datos, metadatos = tfds.load('cats_vs_dogs', as_supervised=True, with_info=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iVXgpz--pUms"
      },
      "outputs": [],
      "source": [
        "#Imprimir los metadatos para revisarlos\n",
        "metadatos"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h18GbmLKsX-a"
      },
      "outputs": [],
      "source": [
        "#Una forma de mostrar 5 ejemplos del set\n",
        "tfds.as_dataframe(datos['train'].take(5), metadatos)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uEGbQbBFsj-a"
      },
      "outputs": [],
      "source": [
        "#Otra forma de mostrar ejemplos del set\n",
        "tfds.show_examples(datos['train'], metadatos)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "19_36Xq5syR5"
      },
      "outputs": [],
      "source": [
        "#Manipular y visualizar el set\n",
        "#Lo pasamos a TAMANO_IMG (100x100) y a blanco y negro (solo para visualizar)\n",
        "import matplotlib.pyplot as plt\n",
        "import cv2\n",
        "\n",
        "#indico el tamapaño de las imagenes usando la funccion figure\n",
        "plt.figure(figsize=(20,20))\n",
        "\n",
        "#varuable de dimension que usaremos en la imagen\n",
        "TAMANO_IMG=100\n",
        "\n",
        "# se crea un indice para pedir que me muestre solo la imagen y la etiqueta\n",
        "for i, (imagen, etiqueta) in enumerate(datos['train'].take(25)):\n",
        "\n",
        "  #usamos cv2 para cambiar el tamaño de la imagen usando la funcion reize\n",
        "  imagen = cv2.resize(imagen.numpy(), (TAMANO_IMG, TAMANO_IMG))\n",
        "\n",
        "  #pasamos las imagenes a blanco y negro para que sea menos tardado\n",
        "  imagen = cv2.cvtColor(imagen, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "  #se usa la funcion subplot para que me muestre Nfila y Ncolumnas, e itere\n",
        "  plt.subplot(5, 5, i+1)\n",
        "\n",
        "  #ticks en arreglo vacio para que no me muestre cuadricula\n",
        "  plt.xticks([])\n",
        "  plt.yticks([])\n",
        "\n",
        "  #mostramos las imagenes\n",
        "  plt.imshow(imagen, cmap='gray')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "zGplClmCyMC-"
      },
      "outputs": [],
      "source": [
        "#Variable que contendra todos los pares de los datos (imagen y etiqueta) ya modificados (blanco y negro, 100x100)\n",
        "datos_entrenamiento = []"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "8sYxRIndyTMG"
      },
      "outputs": [],
      "source": [
        "#iteramos en todos los datos de entenamiento\n",
        "for i, (imagen, etiqueta) in enumerate(datos['train']):\n",
        "  imagen = cv2.resize(imagen.numpy(), (TAMANO_IMG, TAMANO_IMG))\n",
        "  imagen = cv2.cvtColor(imagen, cv2.COLOR_BGR2GRAY)\n",
        "  imagen = imagen.reshape(TAMANO_IMG, TAMANO_IMG, 1) #Cambiar tamano a 100,100,1\n",
        "  datos_entrenamiento.append([imagen, etiqueta])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ODEmYq0zzDlj"
      },
      "outputs": [],
      "source": [
        "#Ver los datos del primer indice (valores de los pixeles)\n",
        "datos_entrenamiento[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6ixaAo5gzk1L"
      },
      "outputs": [],
      "source": [
        "#Ver cuantos datos tengo en la variable\n",
        "len(datos_entrenamiento)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "oxLjpVPCzx2T"
      },
      "outputs": [],
      "source": [
        "#Preparar mis variables X (entradas) y Y (etiquetas) separadas\n",
        "\n",
        "X = [] #imagenes de entrada (pixeles)\n",
        "y = [] #etiquetas (perro o gato)\n",
        "\n",
        "for imagen, etiqueta in datos_entrenamiento:\n",
        "  X.append(imagen)\n",
        "  y.append(etiqueta)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "tOLVDe4n0MMc"
      },
      "outputs": [],
      "source": [
        "#Normalizar los datos de las X (imagenes). Se pasan a numero flotante y dividen entre 255 para quedar de 0-1 en lugar de 0-255\n",
        "import numpy as np\n",
        "\n",
        "X = np.array(X).astype(float) / 255"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "Sr2lGFCT1Az8"
      },
      "outputs": [],
      "source": [
        "#Convertir etiquetas en arreglo simple entre 0 y 1\n",
        "y = np.array(y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VVO5UH2E3C8H"
      },
      "outputs": [],
      "source": [
        "y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "yn5Ai4wt2xZn"
      },
      "outputs": [],
      "source": [
        "#Crear los modelos iniciales\n",
        "#Usan sigmoid como salida (en lugar de softmax) para mostrar como podria funcionar con dicha funcion de activacion.\n",
        "#Sigmoid regresa siempre datos entre 0 y 1. Realizamos el entrenamiento para al final considerar que si la respuesta se\n",
        "#acerca a 0, es un gato, y si se acerca a 1, es un perro.\n",
        "\n",
        "#primero modelo de datos. modelo denso\n",
        "modeloDenso = tf.keras.models.Sequential([\n",
        "  #capa de entrada recibiendo los pixeles\n",
        "  tf.keras.layers.Flatten(input_shape=(100, 100, 1)),\n",
        "\n",
        "  #dos capas de 150 neuronas cada una\n",
        "  tf.keras.layers.Dense(150, activation='relu'),\n",
        "  tf.keras.layers.Dense(150, activation='relu'),\n",
        "\n",
        "  #capa de salida, dejamos 1 sola neurona de salida y utilizamos la activacion sigmoid que siempre devuelve un valor entre 0 y 1\n",
        "  tf.keras.layers.Dense(1, activation='sigmoid')\n",
        "])\n",
        "\n",
        "\n",
        "#segundo modelo de datos usando una red neuronal convolucional\n",
        "modeloCNN = tf.keras.models.Sequential([\n",
        "  #se agregan 3 capas de capas convolucionales y de agrupacion maxima, pasando por 32,64 y 128 filtros\n",
        "  tf.keras.layers.Conv2D(32, (3,3), activation='relu', input_shape=(100, 100, 1)),\n",
        "  tf.keras.layers.MaxPooling2D(2, 2),\n",
        "  tf.keras.layers.Conv2D(64, (3,3), activation='relu'),\n",
        "  tf.keras.layers.MaxPooling2D(2, 2),\n",
        "  tf.keras.layers.Conv2D(128, (3,3), activation='relu'),\n",
        "  tf.keras.layers.MaxPooling2D(2, 2),\n",
        "\n",
        "  #se agraga una capa densa de 100 neuronas y la salida tambien con sigmoid\n",
        "  tf.keras.layers.Flatten(),\n",
        "  tf.keras.layers.Dense(100, activation='relu'),\n",
        "  tf.keras.layers.Dense(1, activation='sigmoid')\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "tXK56vKE7cgh"
      },
      "outputs": [],
      "source": [
        "#Compilamos los modelos con el optimizador \"adam\". Usamos la funcion de perdida crossentropy binario ya que tenemos solo 2 opciones (perro o gato)\n",
        "modeloDenso.compile(optimizer='adam',\n",
        "                    loss='binary_crossentropy',\n",
        "                    metrics=['accuracy'])\n",
        "\n",
        "modeloCNN.compile(optimizer='adam',\n",
        "                    loss='binary_crossentropy',\n",
        "                    metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "MOnQRM2f8B4s"
      },
      "outputs": [],
      "source": [
        "#usamos esta libreria para poder usar TensorBoar\n",
        "from tensorflow.keras.callbacks import TensorBoard"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6bIXcZx68Hm0"
      },
      "outputs": [],
      "source": [
        "#La variable de tensorboard se envia en el arreglo de \"callbacks\"\n",
        "#En este caso guarda datos en la carpeta indicada en cada epoca, de manera que despues\n",
        "#Tensorboard los lee para hacer graficas\n",
        "\n",
        "#creamos la variable TensonBoardDenso para estre entrenamiento del primer modelo\n",
        "tensorboardDenso = TensorBoard(log_dir='logs/denso')\n",
        "#entrenamos el modelo mandando la funcion fit y les envio la X(imagenes), y(etiquetas) y le indico un tamaño de lote\n",
        "modeloDenso.fit(X, y, batch_size=32,\n",
        "                #porcentaje para pruebas del 15%\n",
        "                validation_split=0.15,\n",
        "                #se usan 100 epocas\n",
        "                epochs=100,\n",
        "                #se agrega un arreglo de callback para guardar los resultados de cada epoca\n",
        "                callbacks=[tensorboardDenso])"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#entrenamiento del segundo modelo\n",
        "tensorboardCNN = TensorBoard(log_dir='logs/cnn')\n",
        "modeloCNN.fit(X, y, batch_size=32,\n",
        "                validation_split=0.15,\n",
        "                epochs=100,\n",
        "                callbacks=[tensorboardCNN])"
      ],
      "metadata": {
        "id": "IRIJWGs5SBZK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#ver las imagenes de la variable X sin modificaciones por aumento de datos\n",
        "plt.figure(figsize=(20, 8))\n",
        "for i in range(10):\n",
        "  plt.subplot(2, 5, i+1)\n",
        "  plt.xticks([])\n",
        "  plt.yticks([])\n",
        "  plt.imshow(X[i].reshape(100, 100), cmap=\"gray\")"
      ],
      "metadata": {
        "id": "Le0VBjGySqMy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Realizar el aumento de datos con varias transformaciones. Al final, graficar 10 como ejemplo\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "datagen = ImageDataGenerator(\n",
        "    rotation_range=30,#rotar la imagen de manera aleatoria\n",
        "    width_shift_range=0.2,#mueve la imagen a los los lados\n",
        "    height_shift_range=0.2,#mueve la imagen arriba y abajo\n",
        "    shear_range=15,#se inclina la imagen\n",
        "    zoom_range=[0.7, 1.4],#que tanto se puede hacer el acercamiento a la imagen\n",
        "    horizontal_flip=True,#rotaciones aleatorias horizontal o vertual\n",
        "    vertical_flip=True\n",
        ")\n",
        "\n",
        "datagen.fit(X)\n",
        "\n",
        "plt.figure(figsize=(20,8))\n",
        "\n",
        "for imagen, etiqueta in datagen.flow(X, y, batch_size=10, shuffle=False):\n",
        "  for i in range(10):\n",
        "    plt.subplot(2, 5, i+1)\n",
        "    plt.xticks([])\n",
        "    plt.yticks([])\n",
        "    plt.imshow(imagen[i].reshape(100, 100), cmap=\"gray\")\n",
        "  break"
      ],
      "metadata": {
        "id": "Frq15t36TDaN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "modeloDenso_AD = tf.keras.models.Sequential([\n",
        "  tf.keras.layers.Flatten(input_shape=(100, 100, 1)),\n",
        "  tf.keras.layers.Dense(150, activation='relu'),\n",
        "  tf.keras.layers.Dense(150, activation='relu'),\n",
        "  tf.keras.layers.Dense(1, activation='sigmoid')\n",
        "])\n",
        "\n",
        "modeloCNN_AD = tf.keras.models.Sequential([\n",
        "  tf.keras.layers.Conv2D(32, (3,3), activation='relu', input_shape=(100, 100, 1)),\n",
        "  tf.keras.layers.MaxPooling2D(2, 2),\n",
        "  tf.keras.layers.Conv2D(64, (3,3), activation='relu'),\n",
        "  tf.keras.layers.MaxPooling2D(2, 2),\n",
        "  tf.keras.layers.Conv2D(128, (3,3), activation='relu'),\n",
        "  tf.keras.layers.MaxPooling2D(2, 2),\n",
        "\n",
        "  tf.keras.layers.Flatten(),\n",
        "  tf.keras.layers.Dense(100, activation='relu'),\n",
        "  tf.keras.layers.Dense(1, activation='sigmoid')\n",
        "])"
      ],
      "metadata": {
        "id": "N6wyROMLU44c"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "modeloDenso_AD.compile(optimizer='adam',\n",
        "                    loss='binary_crossentropy',\n",
        "                    metrics=['accuracy'])\n",
        "\n",
        "modeloCNN_AD.compile(optimizer='adam',\n",
        "                    loss='binary_crossentropy',\n",
        "                    metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "fQkohxBQU_Y6"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Separar los datos de entrenamiento y los datos de pruebas en variables diferentes\n",
        "#datos de entrenamiento\n",
        "len(X) * .85 #19700\n",
        "\n",
        "#datos para pruebas\n",
        "len(X) - 19700 #3562\n",
        "\n",
        "#imagenes\n",
        "X_entrenamiento = X[:19700]#85% de entrenamiento\n",
        "X_validacion = X[19700:]#15%para pruebas\n",
        "\n",
        "#etiquetas\n",
        "y_entrenamiento = y[:19700]\n",
        "y_validacion = y[19700:]"
      ],
      "metadata": {
        "id": "gGLx4qGJVBkT"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Usar la funcion flow del generador para crear un iterador que podamos enviar como entrenamiento a la funcion FIT del modelo\n",
        "data_gen_entrenamiento = datagen.flow(X_entrenamiento, y_entrenamiento, batch_size=32)"
      ],
      "metadata": {
        "id": "5n3fwLpMVvG3"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#comando de python para librerar memoria ram\n",
        "import gc\n",
        "gc.collect()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PQfyInl0WRya",
        "outputId": "be7e19c8-a348-4b25-a500-28ead6e65e22"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "19836"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#entrenamiento modelo 1 denso con aumento de datos\n",
        "tensorboardDenso_AD = TensorBoard(log_dir='logs/denso_AD')\n",
        "\n",
        "#funcion fit\n",
        "modeloDenso_AD.fit(\n",
        "    data_gen_entrenamiento,\n",
        "    epochs=100, batch_size=32,\n",
        "    validation_data=(X_validacion, y_validacion),\n",
        "    steps_per_epoch=int(np.ceil(len(X_entrenamiento) / float(32))),\n",
        "    validation_steps=int(np.ceil(len(X_validacion) / float(32))),\n",
        "    callbacks=[tensorboardDenso_AD]\n",
        ")"
      ],
      "metadata": {
        "id": "22NF2h4zV4u1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#entrenamiento modelo 2 convolucional con aumento de datos\n",
        "tensorboardCNN_AD = TensorBoard(log_dir='logs-new/cnn_AD')\n",
        "\n",
        "modeloCNN_AD.fit(\n",
        "    data_gen_entrenamiento,\n",
        "    epochs=150, batch_size=32,\n",
        "    validation_data=(X_validacion, y_validacion),\n",
        "    steps_per_epoch=int(np.ceil(len(X_entrenamiento) / float(32))),\n",
        "    validation_steps=int(np.ceil(len(X_validacion) / float(32))),\n",
        "    callbacks=[tensorboardCNN_AD]\n",
        ")"
      ],
      "metadata": {
        "id": "tmDZ1qOhXS8M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Cargar la extension de tensorboard de colab\n",
        "%load_ext tensorboard"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P5bB4dUDuQUp",
        "outputId": "77ff4ce0-43e9-4c36-998f-5d4c18cef357"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The tensorboard extension is already loaded. To reload it, use:\n",
            "  %reload_ext tensorboard\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Ejecutar tensorboard e indicarle que lea la carpeta \"logs\"\n",
        "%tensorboard --logdir logs"
      ],
      "metadata": {
        "id": "I66YuJpGuW4g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#se guarda el modelo que mejor resultado obtuvo y le indico el nombre\n",
        "modeloCNN_AD.save('perros-gatos-cnn-ad.h5')"
      ],
      "metadata": {
        "id": "5exfx2ckajsf"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#instalamos tensorfliwjs con pip\n",
        "!pip install tensorflowjs"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2wtwoYjka4zx",
        "outputId": "6bcc8f4e-ee70-48be-8228-acd36d92ac67"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting tensorflowjs\n",
            "  Downloading tensorflowjs-4.4.0-py3-none-any.whl (85 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m85.1/85.1 kB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting tensorflow-decision-forests>=1.0.1\n",
            "  Downloading tensorflow_decision_forests-1.3.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (16.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16.4/16.4 MB\u001b[0m \u001b[31m43.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: flax>=0.6.2 in /usr/local/lib/python3.9/dist-packages (from tensorflowjs) (0.6.8)\n",
            "Requirement already satisfied: jax>=0.3.16 in /usr/local/lib/python3.9/dist-packages (from tensorflowjs) (0.4.8)\n",
            "Requirement already satisfied: importlib_resources>=5.9.0 in /usr/local/lib/python3.9/dist-packages (from tensorflowjs) (5.12.0)\n",
            "Requirement already satisfied: tensorflow<3,>=2.10.0 in /usr/local/lib/python3.9/dist-packages (from tensorflowjs) (2.12.0)\n",
            "Requirement already satisfied: six<2,>=1.12.0 in /usr/local/lib/python3.9/dist-packages (from tensorflowjs) (1.16.0)\n",
            "Collecting tensorflow-hub<0.13,>=0.7.0\n",
            "  Downloading tensorflow_hub-0.12.0-py2.py3-none-any.whl (108 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m108.8/108.8 kB\u001b[0m \u001b[31m11.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting packaging~=20.9\n",
            "  Downloading packaging-20.9-py2.py3-none-any.whl (40 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m40.9/40.9 kB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting protobuf<3.20,>=3.9.2\n",
            "  Downloading protobuf-3.19.6-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m39.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: optax in /usr/local/lib/python3.9/dist-packages (from flax>=0.6.2->tensorflowjs) (0.1.4)\n",
            "Requirement already satisfied: PyYAML>=5.4.1 in /usr/local/lib/python3.9/dist-packages (from flax>=0.6.2->tensorflowjs) (6.0)\n",
            "Requirement already satisfied: orbax in /usr/local/lib/python3.9/dist-packages (from flax>=0.6.2->tensorflowjs) (0.1.7)\n",
            "Requirement already satisfied: numpy>=1.12 in /usr/local/lib/python3.9/dist-packages (from flax>=0.6.2->tensorflowjs) (1.22.4)\n",
            "Requirement already satisfied: rich>=11.1 in /usr/local/lib/python3.9/dist-packages (from flax>=0.6.2->tensorflowjs) (13.3.3)\n",
            "Requirement already satisfied: msgpack in /usr/local/lib/python3.9/dist-packages (from flax>=0.6.2->tensorflowjs) (1.0.5)\n",
            "Requirement already satisfied: tensorstore in /usr/local/lib/python3.9/dist-packages (from flax>=0.6.2->tensorflowjs) (0.1.35)\n",
            "Requirement already satisfied: typing-extensions>=4.1.1 in /usr/local/lib/python3.9/dist-packages (from flax>=0.6.2->tensorflowjs) (4.5.0)\n",
            "Requirement already satisfied: zipp>=3.1.0 in /usr/local/lib/python3.9/dist-packages (from importlib_resources>=5.9.0->tensorflowjs) (3.15.0)\n",
            "Requirement already satisfied: opt-einsum in /usr/local/lib/python3.9/dist-packages (from jax>=0.3.16->tensorflowjs) (3.3.0)\n",
            "Requirement already satisfied: scipy>=1.7 in /usr/local/lib/python3.9/dist-packages (from jax>=0.3.16->tensorflowjs) (1.10.1)\n",
            "Requirement already satisfied: ml-dtypes>=0.0.3 in /usr/local/lib/python3.9/dist-packages (from jax>=0.3.16->tensorflowjs) (0.0.4)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.9/dist-packages (from packaging~=20.9->tensorflowjs) (3.0.9)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.9/dist-packages (from tensorflow<3,>=2.10.0->tensorflowjs) (1.6.3)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.9/dist-packages (from tensorflow<3,>=2.10.0->tensorflowjs) (1.53.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.9/dist-packages (from tensorflow<3,>=2.10.0->tensorflowjs) (0.2.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.9/dist-packages (from tensorflow<3,>=2.10.0->tensorflowjs) (67.6.1)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.9/dist-packages (from tensorflow<3,>=2.10.0->tensorflowjs) (2.2.0)\n",
            "Requirement already satisfied: keras<2.13,>=2.12.0 in /usr/local/lib/python3.9/dist-packages (from tensorflow<3,>=2.10.0->tensorflowjs) (2.12.0)\n",
            "Requirement already satisfied: flatbuffers>=2.0 in /usr/local/lib/python3.9/dist-packages (from tensorflow<3,>=2.10.0->tensorflowjs) (23.3.3)\n",
            "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in /usr/local/lib/python3.9/dist-packages (from tensorflow<3,>=2.10.0->tensorflowjs) (0.4.0)\n",
            "Requirement already satisfied: wrapt<1.15,>=1.11.0 in /usr/local/lib/python3.9/dist-packages (from tensorflow<3,>=2.10.0->tensorflowjs) (1.14.1)\n",
            "Requirement already satisfied: tensorflow-estimator<2.13,>=2.12.0 in /usr/local/lib/python3.9/dist-packages (from tensorflow<3,>=2.10.0->tensorflowjs) (2.12.0)\n",
            "Collecting tensorflow<3,>=2.10.0\n",
            "  Downloading tensorflow-2.11.1-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (588.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m588.3/588.3 MB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting tensorboard<2.12,>=2.11\n",
            "  Downloading tensorboard-2.11.2-py3-none-any.whl (6.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.0/6.0 MB\u001b[0m \u001b[31m21.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting tensorflow-estimator<2.12,>=2.11.0\n",
            "  Downloading tensorflow_estimator-2.11.0-py2.py3-none-any.whl (439 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m439.2/439.2 kB\u001b[0m \u001b[31m22.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting keras<2.12,>=2.11.0\n",
            "  Downloading keras-2.11.0-py2.py3-none-any.whl (1.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m25.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.9/dist-packages (from tensorflow<3,>=2.10.0->tensorflowjs) (0.32.0)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.9/dist-packages (from tensorflow<3,>=2.10.0->tensorflowjs) (1.4.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.9/dist-packages (from tensorflow<3,>=2.10.0->tensorflowjs) (16.0.0)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.9/dist-packages (from tensorflow<3,>=2.10.0->tensorflowjs) (3.8.0)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.9/dist-packages (from tensorflow-decision-forests>=1.0.1->tensorflowjs) (1.5.3)\n",
            "Collecting wurlitzer\n",
            "  Downloading wurlitzer-3.0.3-py3-none-any.whl (7.3 kB)\n",
            "Requirement already satisfied: wheel in /usr/local/lib/python3.9/dist-packages (from tensorflow-decision-forests>=1.0.1->tensorflowjs) (0.40.0)\n",
            "INFO: pip is looking at multiple versions of tensorflow-decision-forests to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting tensorflow-decision-forests>=1.0.1\n",
            "  Downloading tensorflow_decision_forests-1.2.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (16.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16.5/16.5 MB\u001b[0m \u001b[31m8.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: markdown-it-py<3.0.0,>=2.2.0 in /usr/local/lib/python3.9/dist-packages (from rich>=11.1->flax>=0.6.2->tensorflowjs) (2.2.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.9/dist-packages (from rich>=11.1->flax>=0.6.2->tensorflowjs) (2.14.0)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.9/dist-packages (from tensorboard<2.12,>=2.11->tensorflow<3,>=2.10.0->tensorflowjs) (2.17.2)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.9/dist-packages (from tensorboard<2.12,>=2.11->tensorflow<3,>=2.10.0->tensorflowjs) (3.4.3)\n",
            "Collecting google-auth-oauthlib<0.5,>=0.4.1\n",
            "  Downloading google_auth_oauthlib-0.4.6-py2.py3-none-any.whl (18 kB)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.9/dist-packages (from tensorboard<2.12,>=2.11->tensorflow<3,>=2.10.0->tensorflowjs) (2.27.1)\n",
            "Collecting tensorboard-data-server<0.7.0,>=0.6.0\n",
            "  Downloading tensorboard_data_server-0.6.1-py3-none-manylinux2010_x86_64.whl (4.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.9/4.9 MB\u001b[0m \u001b[31m56.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.9/dist-packages (from tensorboard<2.12,>=2.11->tensorflow<3,>=2.10.0->tensorflowjs) (2.2.3)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.9/dist-packages (from tensorboard<2.12,>=2.11->tensorflow<3,>=2.10.0->tensorflowjs) (1.8.1)\n",
            "Requirement already satisfied: jaxlib>=0.1.37 in /usr/local/lib/python3.9/dist-packages (from optax->flax>=0.6.2->tensorflowjs) (0.4.7+cuda11.cudnn86)\n",
            "Requirement already satisfied: chex>=0.1.5 in /usr/local/lib/python3.9/dist-packages (from optax->flax>=0.6.2->tensorflowjs) (0.1.7)\n",
            "Requirement already satisfied: cached_property in /usr/local/lib/python3.9/dist-packages (from orbax->flax>=0.6.2->tensorflowjs) (1.5.2)\n",
            "Requirement already satisfied: nest_asyncio in /usr/local/lib/python3.9/dist-packages (from orbax->flax>=0.6.2->tensorflowjs) (1.5.6)\n",
            "Requirement already satisfied: etils in /usr/local/lib/python3.9/dist-packages (from orbax->flax>=0.6.2->tensorflowjs) (1.2.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.9/dist-packages (from pandas->tensorflow-decision-forests>=1.0.1->tensorflowjs) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.9/dist-packages (from pandas->tensorflow-decision-forests>=1.0.1->tensorflowjs) (2022.7.1)\n",
            "Requirement already satisfied: dm-tree>=0.1.5 in /usr/local/lib/python3.9/dist-packages (from chex>=0.1.5->optax->flax>=0.6.2->tensorflowjs) (0.1.8)\n",
            "Requirement already satisfied: toolz>=0.9.0 in /usr/local/lib/python3.9/dist-packages (from chex>=0.1.5->optax->flax>=0.6.2->tensorflowjs) (0.12.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.9/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.12,>=2.11->tensorflow<3,>=2.10.0->tensorflowjs) (4.9)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.9/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.12,>=2.11->tensorflow<3,>=2.10.0->tensorflowjs) (0.2.8)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.9/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.12,>=2.11->tensorflow<3,>=2.10.0->tensorflowjs) (5.3.0)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.9/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.12,>=2.11->tensorflow<3,>=2.10.0->tensorflowjs) (1.3.1)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.9/dist-packages (from markdown>=2.6.8->tensorboard<2.12,>=2.11->tensorflow<3,>=2.10.0->tensorflowjs) (6.3.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.9/dist-packages (from markdown-it-py<3.0.0,>=2.2.0->rich>=11.1->flax>=0.6.2->tensorflowjs) (0.1.2)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.9/dist-packages (from requests<3,>=2.21.0->tensorboard<2.12,>=2.11->tensorflow<3,>=2.10.0->tensorflowjs) (2022.12.7)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.9/dist-packages (from requests<3,>=2.21.0->tensorboard<2.12,>=2.11->tensorflow<3,>=2.10.0->tensorflowjs) (3.4)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.9/dist-packages (from requests<3,>=2.21.0->tensorboard<2.12,>=2.11->tensorflow<3,>=2.10.0->tensorflowjs) (2.0.12)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/dist-packages (from requests<3,>=2.21.0->tensorboard<2.12,>=2.11->tensorflow<3,>=2.10.0->tensorflowjs) (1.26.15)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.9/dist-packages (from werkzeug>=1.0.1->tensorboard<2.12,>=2.11->tensorflow<3,>=2.10.0->tensorflowjs) (2.1.2)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.9/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.12,>=2.11->tensorflow<3,>=2.10.0->tensorflowjs) (0.4.8)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.9/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.12,>=2.11->tensorflow<3,>=2.10.0->tensorflowjs) (3.2.2)\n",
            "Installing collected packages: wurlitzer, tensorflow-estimator, tensorboard-data-server, protobuf, packaging, keras, tensorflow-hub, google-auth-oauthlib, tensorboard, tensorflow, tensorflow-decision-forests, tensorflowjs\n",
            "  Attempting uninstall: tensorflow-estimator\n",
            "    Found existing installation: tensorflow-estimator 2.12.0\n",
            "    Uninstalling tensorflow-estimator-2.12.0:\n",
            "      Successfully uninstalled tensorflow-estimator-2.12.0\n",
            "  Attempting uninstall: tensorboard-data-server\n",
            "    Found existing installation: tensorboard-data-server 0.7.0\n",
            "    Uninstalling tensorboard-data-server-0.7.0:\n",
            "      Successfully uninstalled tensorboard-data-server-0.7.0\n",
            "  Attempting uninstall: protobuf\n",
            "    Found existing installation: protobuf 3.20.3\n",
            "    Uninstalling protobuf-3.20.3:\n",
            "      Successfully uninstalled protobuf-3.20.3\n",
            "  Attempting uninstall: packaging\n",
            "    Found existing installation: packaging 23.0\n",
            "    Uninstalling packaging-23.0:\n",
            "      Successfully uninstalled packaging-23.0\n",
            "  Attempting uninstall: keras\n",
            "    Found existing installation: keras 2.12.0\n",
            "    Uninstalling keras-2.12.0:\n",
            "      Successfully uninstalled keras-2.12.0\n",
            "  Attempting uninstall: tensorflow-hub\n",
            "    Found existing installation: tensorflow-hub 0.13.0\n",
            "    Uninstalling tensorflow-hub-0.13.0:\n",
            "      Successfully uninstalled tensorflow-hub-0.13.0\n",
            "  Attempting uninstall: google-auth-oauthlib\n",
            "    Found existing installation: google-auth-oauthlib 1.0.0\n",
            "    Uninstalling google-auth-oauthlib-1.0.0:\n",
            "      Successfully uninstalled google-auth-oauthlib-1.0.0\n",
            "  Attempting uninstall: tensorboard\n",
            "    Found existing installation: tensorboard 2.12.1\n",
            "    Uninstalling tensorboard-2.12.1:\n",
            "      Successfully uninstalled tensorboard-2.12.1\n",
            "  Attempting uninstall: tensorflow\n",
            "    Found existing installation: tensorflow 2.12.0\n",
            "    Uninstalling tensorflow-2.12.0:\n",
            "      Successfully uninstalled tensorflow-2.12.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "xarray 2022.12.0 requires packaging>=21.3, but you have packaging 20.9 which is incompatible.\n",
            "statsmodels 0.13.5 requires packaging>=21.3, but you have packaging 20.9 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed google-auth-oauthlib-0.4.6 keras-2.11.0 packaging-20.9 protobuf-3.19.6 tensorboard-2.11.2 tensorboard-data-server-0.6.1 tensorflow-2.11.1 tensorflow-decision-forests-1.2.0 tensorflow-estimator-2.11.0 tensorflow-hub-0.12.0 tensorflowjs-4.4.0 wurlitzer-3.0.3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#se crea una capeta para guardar el modelo\n",
        "!mkdir carpeta_salida"
      ],
      "metadata": {
        "id": "O5Olet32a5qk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#exportamos el modelo H5 al formato de tensrflowjs para usarlo en un explorador\n",
        "!tensorflowjs_converter --input_format keras perros-gatos-cnn-ad.h5 carpeta_salida"
      ],
      "metadata": {
        "id": "hHF2hef_a7Nd"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}